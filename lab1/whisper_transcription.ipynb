{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0399facc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\kupit\\miniconda3\\envs\\py311\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6ea366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 2025-10-12-git-0bc54cddb1-full_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "built with gcc 15.2.0 (Rev8, Built by MSYS2 project)\n",
      "configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-lcms2 --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-libdvdnav --enable-libdvdread --enable-sdl2 --enable-libaribb24 --enable-libaribcaption --enable-libdav1d --enable-libdavs2 --enable-libopenjpeg --enable-libquirc --enable-libuavs3d --enable-libxevd --enable-libzvbi --enable-liboapv --enable-libqrencode --enable-librav1e --enable-libsvtav1 --enable-libvvenc --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxeve --enable-libxvid --enable-libaom --enable-libjxl --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-openal --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libcodec2 --enable-libilbc --enable-libgsm --enable-liblc3 --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint --enable-whisper\n",
      "libavutil      60. 13.100 / 60. 13.100\n",
      "libavcodec     62. 16.100 / 62. 16.100\n",
      "libavformat    62.  6.101 / 62.  6.101\n",
      "libavdevice    62.  2.100 / 62.  2.100\n",
      "libavfilter    11.  9.100 / 11.  9.100\n",
      "libswscale      9.  3.100 /  9.  3.100\n",
      "libswresample   6.  2.100 /  6.  2.100\n",
      "\n",
      "Exiting with exit code 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"ffmpeg\", \"-version\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9833707",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2466941882.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mchoco install ffmpeg\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "choco install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87266bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file verification:\n",
      "- Path: C:\\Users\\kupit\\week 1\\d4\\lab1\\ALDDEBWDBIUQND8A-M-b256-e8a94.mp4\n",
      "- File size: 23.83 MB\n",
      "- File format: .mp4\n",
      "Audio file is accessible.\n",
      "\n",
      "Extracting first 60 seconds of audio...\n",
      "Trimmed audio saved to: C:\\Users\\kupit\\week 1\\d4\\lab1\\audio_first_60_seconds.wav\n",
      "\n",
      "Transcription completed successfully.\n",
      "Transcription saved to: C:\\Users\\kupit\\week 1\\d4\\lab1\\transcription_first_minute.txt\n",
      "\n",
      "Transcription preview:\n",
      "---------------------\n",
      "The following was recorded from Dictionary of American Regional English Tape 1-2-3-2, Side 1. This is a recording of Mrs. Nettie made at McConnellsville, Morgan County, Ohio, on the 21st of February, 1968, by The etched tape was used to record Nathaniel Noble's patch number 1666, and the staff of the local public information agency reviewed it and refactored it with the text, in addition to inviting the audience parts to be cleaned. We'll now hear Mrs. Nettie Nettie The story of Arthur the Rat. Once upon a time there was a young rat who couldn't make up his mind.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "\n",
    "# Path to the original audio file\n",
    "AUDIO_PATH = r\"C:\\Users\\kupit\\week 1\\d4\\lab1\\ALDDEBWDBIUQND8A-M-b256-e8a94.mp4\"\n",
    "\n",
    "# Temporary trimmed audio file (first 60 seconds)\n",
    "TRIMMED_AUDIO_PATH = r\"C:\\Users\\kupit\\week 1\\d4\\lab1\\audio_first_60_seconds.wav\"\n",
    "\n",
    "# Output transcription file\n",
    "OUTPUT_TEXT_PATH = r\"C:\\Users\\kupit\\week 1\\d4\\lab1\\transcription_first_minute.txt\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Verify audio file\n",
    "# -----------------------------\n",
    "\n",
    "if not os.path.exists(AUDIO_PATH):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {AUDIO_PATH}\")\n",
    "\n",
    "file_size_mb = os.path.getsize(AUDIO_PATH) / (1024 * 1024)\n",
    "file_extension = os.path.splitext(AUDIO_PATH)[1]\n",
    "\n",
    "print(\"Audio file verification:\")\n",
    "print(f\"- Path: {AUDIO_PATH}\")\n",
    "print(f\"- File size: {file_size_mb:.2f} MB\")\n",
    "print(f\"- File format: {file_extension}\")\n",
    "print(\"Audio file is accessible.\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2.1: Extract first 60 seconds\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Extracting first 60 seconds of audio...\")\n",
    "\n",
    "audio = AudioSegment.from_file(AUDIO_PATH)\n",
    "first_minute_audio = audio[:60 * 1000]  # 60 seconds in milliseconds\n",
    "\n",
    "first_minute_audio.export(TRIMMED_AUDIO_PATH, format=\"wav\")\n",
    "\n",
    "print(f\"Trimmed audio saved to: {TRIMMED_AUDIO_PATH}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Transcribe trimmed audio\n",
    "# -----------------------------\n",
    "\n",
    "with open(TRIMMED_AUDIO_PATH, \"rb\") as audio_file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        file=audio_file,\n",
    "        model=\"whisper-1\",\n",
    "    )\n",
    "\n",
    "transcription_text = transcription.text\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3.1: Save transcription\n",
    "# -----------------------------\n",
    "\n",
    "with open(OUTPUT_TEXT_PATH, \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(transcription_text)\n",
    "\n",
    "# -----------------------------\n",
    "# Output results\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Transcription completed successfully.\")\n",
    "print(f\"Transcription saved to: {OUTPUT_TEXT_PATH}\\n\")\n",
    "\n",
    "print(\"Transcription preview:\")\n",
    "print(\"---------------------\")\n",
    "print(transcription_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e16b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 3\n",
      "[No Prompt] Transcribing chunk 1/3 ...\n",
      "[No Prompt] Transcribing chunk 2/3 ...\n",
      "[No Prompt] Transcribing chunk 3/3 ...\n",
      "[With Prompt] Transcribing chunk 1/3 ...\n",
      "[With Prompt] Transcribing chunk 2/3 ...\n",
      "[With Prompt] Transcribing chunk 3/3 ...\n",
      "All transcriptions completed: TXT, JSON, SRT for both versions with timestamps.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "AUDIO_PATH = r\"C:\\Users\\kupit\\week 1\\d4\\lab1\\ALDDEBWDBIUQND8A-M-b256-e8a94.mp4\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\kupit\\week 1\\d4\\lab1\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# -----------------------------\n",
    "# Load original audio\n",
    "# -----------------------------\n",
    "audio = AudioSegment.from_file(AUDIO_PATH)\n",
    "\n",
    "# Limit to first 3 minutes\n",
    "audio = audio[:3 * 60 * 1000]\n",
    "\n",
    "# -----------------------------\n",
    "# Split into 60-second chunks\n",
    "# -----------------------------\n",
    "chunk_length_ms = 60 * 1000  # 60 seconds\n",
    "chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")  # should be 3\n",
    "\n",
    "# -----------------------------\n",
    "# Shorter robust prompt\n",
    "# -----------------------------\n",
    "guided_prompt = (\n",
    "    \"Transcribe this recorded meeting as accurately as possible. \"\n",
    "    \"Audio may be quiet, unclear, or noisy. \"\n",
    "    \"Preserve names, acronyms, and technical terms. \"\n",
    "    \"Include full sentences and punctuation.\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Helper function to transcribe chunks\n",
    "# -----------------------------\n",
    "def transcribe_chunk(chunk, prompt=None, skip_empty=True):\n",
    "    temp_chunk_path = \"temp_chunk.wav\"\n",
    "    chunk.export(temp_chunk_path, format=\"wav\")\n",
    "\n",
    "    if skip_empty and chunk.dBFS < -50:\n",
    "        os.remove(temp_chunk_path)\n",
    "        return \"\", 0, 0  # return empty text with start/end\n",
    "\n",
    "    start_ms = chunk.start_time if hasattr(chunk, \"start_time\") else 0\n",
    "    end_ms = start_ms + len(chunk)\n",
    "\n",
    "    with open(temp_chunk_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\",\n",
    "            prompt=prompt,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "    os.remove(temp_chunk_path)\n",
    "    return transcription.strip(), start_ms, end_ms\n",
    "\n",
    "# -----------------------------\n",
    "# Functions to save with timestamps\n",
    "# -----------------------------\n",
    "def save_txt(chunks_info, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, (text, start_ms, end_ms) in enumerate(chunks_info):\n",
    "            f.write(f\"--- Chunk {idx+1} ---\\n\")\n",
    "            f.write(f\"Start: {start_ms} ms, End: {end_ms} ms\\n\")\n",
    "            f.write(f\"{text}\\n\\n\")\n",
    "\n",
    "def save_json(chunks_info, path):\n",
    "    data = [{\"chunk\": idx+1, \"start_ms\": start_ms, \"end_ms\": end_ms, \"text\": text} \n",
    "            for idx, (text, start_ms, end_ms) in enumerate(chunks_info)]\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def save_srt(chunks_info, path):\n",
    "    def ms_to_srt_time(ms):\n",
    "        h = ms // 3600000\n",
    "        m = (ms % 3600000) // 60000\n",
    "        s = (ms % 60000) // 1000\n",
    "        ms_rem = ms % 1000\n",
    "        return f\"{h:02}:{m:02}:{s:02},{ms_rem:03}\"\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, (text, start_ms, end_ms) in enumerate(chunks_info):\n",
    "            f.write(f\"{idx+1}\\n\")\n",
    "            f.write(f\"{ms_to_srt_time(start_ms)} --> {ms_to_srt_time(end_ms)}\\n\")\n",
    "            f.write(f\"{text}\\n\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Transcription for a version\n",
    "# -----------------------------\n",
    "def transcribe_version(prompt, skip_empty, prefix):\n",
    "    chunks_info = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        # add start_time attribute for SRT and timestamps\n",
    "        chunk.start_time = idx * chunk_length_ms\n",
    "        version_name = \"With Prompt\" if prompt else \"No Prompt\"\n",
    "        print(f\"[{version_name}] Transcribing chunk {idx+1}/{len(chunks)} ...\")\n",
    "        text, start_ms, end_ms = transcribe_chunk(chunk, prompt=prompt, skip_empty=skip_empty)\n",
    "        chunks_info.append((text, start_ms, end_ms))\n",
    "\n",
    "    # Save in all formats\n",
    "    save_txt(chunks_info, os.path.join(OUTPUT_DIR, f\"{prefix}.txt\"))\n",
    "    save_json(chunks_info, os.path.join(OUTPUT_DIR, f\"{prefix}.json\"))\n",
    "    save_srt(chunks_info, os.path.join(OUTPUT_DIR, f\"{prefix}.srt\"))\n",
    "\n",
    "# -----------------------------\n",
    "# Run baseline (no prompt)\n",
    "# -----------------------------\n",
    "transcribe_version(prompt=None, skip_empty=True, prefix=\"transcription_no_prompt_3min\")\n",
    "\n",
    "# -----------------------------\n",
    "# Run guided prompt version\n",
    "# -----------------------------\n",
    "transcribe_version(prompt=guided_prompt, skip_empty=False, prefix=\"transcription_with_prompt_3min\")\n",
    "\n",
    "print(\"All transcriptions completed: TXT, JSON, SRT for both versions with timestamps.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
